{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c5bb79-a9dd-48b4-87ba-c09716be8d6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Agents that can code\n",
    "\n",
    "We are now going to start using chatGPT4o because it can code better than chatGPT3.5. But remember that chatGPT4o is more expensive per token than chatGPT3.5 so keep an eye on your usage here: https://platform.openai.com/usage\n",
    "\n",
    "> **From now on, we will not execute the code in the Jupyter notebook, this is because of two reasons:**\n",
    "> 1. We are going to ask our agents to write code and execute it for us. Executing code by an agent inside a Jupyter notebook can be tricky and requires additional configuration. It also depends of the OS being used. To avoid dealing with these issues, we will simply move on to executing scripts instead of notebooks\n",
    "> 2. We are going to start preparing our code to be able to deploy it on the cloud later, so that we can share a link towards our Agents based app. It is not possible to deploy notebooks, so we are going to start using scripts to get ready for that.\n",
    "> We are still going to use notebooks to describe and explain our code, but do not execute the code here, instead use the script version of this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c30874-fcf2-491e-9310-a2d347894c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll always have to start by creating a llm_config object to configure our agents\n",
    "llm_config = {\n",
    "    \"model\": \"gpt-4o\", \n",
    "    \"api_key\": \"sk-proj-GjIUEqAKI2j04dlC18rZT3BlbkFJnLTC5AeosFLwmSAxKzNU\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c341f82-9dc8-43da-855f-1f64cb69d6ea",
   "metadata": {},
   "source": [
    "## Command Line Executor\n",
    "\n",
    "This time, we are going to need to use a new tool from autogen. This tool will allow us to execute code locally on our machine. There are two version of this tool, one that relies on Docker and that will create a virtualized version of a python machine to execute the code; and another one that executes the code locally directly on your machine as we've been doing for this class. The Docker version is more secure, because the code always gets executed within a virtual machine and if the LLM generates malicious code, you will not be executing it directly on your machine. But in the context of this class, we will be generating simple code that we will review each time so we will rely on the simpler version to setup that executes code locally.\n",
    "\n",
    "Let's import this class from autogen and let's setup a local executor environment for our agents.\n",
    "We are going to specify that if the code hangs and nothing happens during 60 seconds we will interrupt it and that we want all the code to execute and provide results in the `coding` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab39a1-c56a-4ab8-a7ee-132e046cbb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## making a Command Line Executor\n",
    "from autogen.code_utils import create_virtual_env\n",
    "from autogen.coding import CodeBlock, LocalCommandLineCodeExecutor\n",
    "\n",
    "venv_dir = \".env_llm\"     #virtual environ directory name\n",
    "                           ##the visual environ that we'll not be using but only the agents will be\n",
    "venv_context = create_virtual_env(venv_dir)\n",
    "\n",
    "executor = LocalCommandLineCodeExecutor(\n",
    "    virtual_env_context=venv_context,\n",
    "    timeout=200,            ## it is the number of seconds after which we will interrupt our agent because there can be a problem if it is taking too long\n",
    "    work_dir=\"coding\",         ## name of the new folder that will be created to store the python scripts and other scripts\n",
    ")\n",
    "print(\n",
    "    executor.execute_code_blocks(code_blocks=[CodeBlock(language=\"python\", code=\"import sys; print(sys.executable)\")])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c31b1c8-b84c-40c8-92e8-3f7ad82a9036",
   "metadata": {},
   "source": [
    "## Code executor agent\n",
    "\n",
    "We are now going to create two agents:\n",
    "1. A **code_writer_agent**: this agent is our engineer, it will rely on chatGPT to generate python code (other languages are currently not supported by autogen) to accomplish the requested task.\n",
    "This agent is not a `ConverseableAgent`, it is one of its subcategories, the `AssistantAgent`. The `AssistantAgent` is designed to write code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81f2d8a-411a-4612-94bc-1034745c5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent\n",
    "\n",
    "# Agent that writes code\n",
    "code_writer_agent = AssistantAgent(\n",
    "    name=\"code_writer_agent\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2d07a9-1e7a-4a48-9c5e-129ebbeb8d9d",
   "metadata": {},
   "source": [
    "This agent does not execute code (`code_execution_config=False`) and we do not need to specify a system prompt message for this agent because it already has a default one that is designed to suggest python code when it can help. We can see the default system prompt message odf this type of agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3e5dd-2822-4a05-a79d-24ed64615ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_writer_agent_system_message = code_writer_agent.system_message\n",
    "print(code_writer_agent_system_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a962f6bc-8cd6-4de9-9081-11e102773763",
   "metadata": {},
   "source": [
    "2. Our second type of agent is a **code_executor_agent**: this agent does not use an LLM (`llm_config=False`), this agent will simply execute code it was provided, locally in the `coding` folder, and send back the result of that code as a reply.  \n",
    "This agent needs a `code_execution_config` to be able to execute code, and we will provide it with the one we defined earlier and that was called `executor` (`code_execution_config={\"executor\": executor}`). We will also give it a default auto reply that it will use if the user does not have any additional details to provide. Basically, each time this agent will execute some code, it will request feedback from the user, you, and if the user does not provide any feedback, it will use the auto reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f014ce-284c-46f3-a2e6-9246c542bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "# Code executor agent\n",
    "code_executor_agent = ConversableAgent(\n",
    "    name=\"code_executor_agent\",\n",
    "    llm_config=False,\n",
    "    code_execution_config={\"executor\": executor},\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    default_auto_reply=\n",
    "    \"Please continue. If everything is done, reply 'TERMINATE'.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4300a0-0f02-4cfe-b573-c8143cadf8f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Coding task\n",
    "\n",
    "We will now ask our agents to perform a task that requires coding. The task will be provided to the Code Writer agent by the Code Executor agent, the Code Writer agent will then propose a code that should fulfill the task, the Code Executor agent will then execute that code and report back the resutl to the Code Writer. There might be several exchanges between these two agents until they accomplish the task.  \n",
    "For example, if a code error is encountered, the error will be reported to the Code Writer who'll propose a corrected version of the code.\n",
    "\n",
    "Let's prepare a simple task to test our code execution scheme. We want our agents to generate a plot that shows the price evolution of two assets, NVDA and BTC for the last 4 years in a way that makes it easy for us to compare them. We will also add the 50 weeks moving average. Let's write it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74923fa-8793-496b-85cf-6b98e11d8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "today = datetime.datetime.now().date()\n",
    "\n",
    "message = f\"Today is {today}. \"\\\n",
    "\"Create a plot showing the normalized price of NVDA and BTC-USD for the last 4 years \"\\\n",
    "\"with their 50 weeks moving average. \"\\\n",
    "\"Make sure the code is in a markdown code block, save the figure\"\\\n",
    "\" to a file asset_analysis.png and show it. Provide all the code necessary in a single python bloc. \"\\\n",
    "\"Re-provide the code block that needs to be executed with each of your messages. \"\\\n",
    "\"If python packages are necessary to execute the code, provide a markdown \"\\\n",
    "\"sh block with only the command necessary to install them and no comments.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d796d-9150-455e-b89c-06c7a380735f",
   "metadata": {},
   "source": [
    "During the execution, the executor might (and will most likely will especially if it is the first time) encounter some errors. For example, if you did not install the modules required by the code writer, you will get an error. You will most likely have to go install these packages yourself in your virtual environment, as we did when we installed `openai`. The agents might also just install the missing moduels themselves.\n",
    "\n",
    "For this task, the code writer will most likely require `matplotlib` and maybe (not necessarily) `pandas`. The LLMs will however tell you how to install missing packages as they will be able to interprete the output of the code and tell you how to fix it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf07c14-81f3-4da0-898d-b321c17e7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_result = code_executor_agent.initiate_chat(\n",
    "    code_writer_agent,\n",
    "    message=message\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7994e139-a4dc-40e4-bbed-ca1cfcb7e8a8",
   "metadata": {},
   "source": [
    "The code will now execute.\n",
    "\n",
    "Take the time to observe the interaction between the agents. Before executing the code provided by the Code Writer, you will be requested to provide feedback. That is an important safety feature. Always review the code written by an agent before executing it, you never know, there might be some malicious content. You can also provide feedback if you take something is wrong with the code. If not, you can just press Enter to let the Code Executor go ahead and execute the code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
